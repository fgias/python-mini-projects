{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arnoldi iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krylov subspaces and the power iteration\n",
    "\n",
    "An intuitive method for finding the largest (in absolute value) eigenvalue of a given m × m matrix $A$ is the power iteration: starting with an arbitrary initial vector b, calculate $Ab$, $A^2b$, $A^3b$,… normalizing the result after every application of the matrix $A$.\n",
    "\n",
    "\n",
    "This sequence converges to the eigenvector corresponding to the eigenvalue with the largest absolute value, $\\lambda _{1}$. However, much potentially useful computation is wasted by using only the final result, $A^{n-1}b$. This suggests that instead, we form the so-called Krylov matrix: $$ K_{n}=[ b\\ Ab\\ A^{2}b\\ \\cdots\\ A^{n-1}b].$$\n",
    "\n",
    "\n",
    "The columns of this matrix are not in general orthogonal, but we can extract an orthogonal basis, via a method such as Gram–Schmidt orthogonalization. The resulting set of vectors is thus an orthogonal basis of the Krylov subspace, $\\mathcal{K}_{n}$. We may expect the vectors of this basis to span good approximations of the eigenvectors corresponding to the $n$ largest eigenvalues, for the same reason that $A^{{n-1}}b$ approximates the dominant eigenvector.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Arnoldi_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Arnoldi iteration\n",
    "\n",
    "The Arnoldi iteration uses the modified Gram–Schmidt process to produce a sequence of orthonormal vectors, $q_1, q_2, q_3, ...$, called the Arnoldi vectors, such that for every $n$, the vectors $q_1, q_2, q_3, ...$ span the Krylov subspace  ${\\mathcal  {K}}_{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def arnoldi_iteration(A, b, n: int):\n",
    "    \"\"\"Computes a basis of the (n + 1)-Krylov subspace of A: the space\n",
    "    spanned by {b, Ab, ..., A^n b}.\n",
    "\n",
    "    Arguments\n",
    "      A: m × m array\n",
    "      b: initial vector (length m)\n",
    "      n: dimension of Krylov subspace, must be >= 1\n",
    "    \n",
    "    Returns\n",
    "      Q: m x (n + 1) array, the columns are an orthonormal basis of the\n",
    "        Krylov subspace.\n",
    "      h: (n + 1) x n array, A on basis Q. It is upper Hessenberg.  \n",
    "    \"\"\"\n",
    "    eps = 1e-12\n",
    "    h = np.zeros((n+1,n))\n",
    "    Q = np.zeros((A.shape[0],n+1))\n",
    "     # Normalize the input vector\n",
    "    Q[:,0] =b/np.linalg.norm(b,2)   # Use it as the first Krylov vector\n",
    "    for k in range(1,n+1):\n",
    "        v = np.dot(A,Q[:,k-1])  # Generate a new candidate vector\n",
    "        for j in range(k):  # Subtract the projections on previous vectors\n",
    "            h[j,k-1] = np.dot(Q[:,j].T, v)\n",
    "            v = v - h[j,k-1] * Q[:,j]\n",
    "        h[k,k-1] = np.linalg.norm(v,2)\n",
    "        if h[k,k-1] > eps:  # Add the produced vector to the list, unless\n",
    "            Q[:,k] = v/h[k,k-1]\n",
    "        else:  # If that happens, stop iterating.\n",
    "            return Q, h\n",
    "    return Q, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krylov subspace\n",
    "\n",
    "Krylov subspaces are used in algorithms for finding approximate solutions to high-dimensional linear algebra problems. Many linear dynamical system tests in control theory, especially those related to controllability and observability, involve checking the rank of the Krylov subspace. These tests are equivalent to finding the span of the Grammians associated with the system/output maps so the uncontrollable and unobservable subspaces are simply the orthogonal complement to the Krylov subspace.\n",
    "\n",
    "Modern iterative methods such as Arnoldi iteration can be used for finding one (or a few) eigenvalues of large sparse matrices or solving large systems of linear equations. They try to avoid matrix-matrix operations, but rather multiply vectors by the matrix and work with the resulting vectors. Starting with a vector $b$, one computes $Ab$, then one multiplies that vector by $A$ to find $A^{2}b$ and so on. All algorithms that work this way are referred to as Krylov subspace methods; they are among the most successful methods currently available in numerical linear algebra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Arnoldi procedure produces a basis $V_m$ of $\\mathcal{K}_m$  and an upper Hesseberg matrix $H_m$ of dimension $m \\times m$ with coefficients $h_{ij}$. We obtain $$ H_m = V_m^T A V_m .$$ Therefore $H_m$, is the projection of the linear transformation $A$ onto the Krylov subspace $\\mathcal{K}_m$ with respect to the basis $V_m$.\n",
    "\n",
    "\n",
    "Given that $H_m$ is a projection of the linear operator, an approximation can be made such that $$ e^{t A} v = |v| V_m e^{t H_m} e_1 .$$\n",
    "\n",
    "http://indico.ictp.it/event/8344/session/55/contribution/226/material/slides/0.pdf"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "220aead3132f0891d2d01f0ad3f05436e31d9e402ae7ff7c9805c7d2dd3b8248"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
